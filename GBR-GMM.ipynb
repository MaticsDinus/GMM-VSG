{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbfc6a7f",
   "metadata": {},
   "source": [
    "# Predict use GMMVSG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd                                              \n",
    "import numpy as np                                       \n",
    "import matplotlib.pyplot as plt   \n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_error  \n",
    "from numpy import mean\n",
    "from numpy import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3613d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.read_excel('Heterocyclic.xlsx')\n",
    "x = data.drop(columns='IE')\n",
    "y = data['IE']\n",
    "\n",
    "# Standardize the data\n",
    "scaler = RobustScaler()\n",
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54870d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the range of number of components to try\n",
    "n_components_range = range(1, 12)\n",
    "\n",
    "# calculate AIC for each number of components\n",
    "aics = []\n",
    "for n_components in n_components_range:\n",
    "    gmm = GaussianMixture(n_components=n_components, covariance_type='full')\n",
    "    gmm.fit(x)\n",
    "    aics.append(gmm.aic(x))\n",
    "\n",
    "# select the optimal number of components based on the AIC\n",
    "best_n_components = n_components_range[np.argmin(aics)]\n",
    "\n",
    "# fit GMM on the dataset with the optimal number of components\n",
    "gmm = GaussianMixture(n_components=best_n_components, covariance_type='full')\n",
    "gmm.fit(x)\n",
    "\n",
    "# generate virtual samples for the input features using GMM\n",
    "n_samples = 1000\n",
    "x_vs, _ = gmm.sample(n_samples)\n",
    "\n",
    "# Concatenate original and virtual samples\n",
    "x_aug = np.concatenate([x, x_vs])\n",
    "\n",
    "# inverse transform the scaled data back to the original scale\n",
    "x_new = scaler.inverse_transform(x_aug)\n",
    "\n",
    "# generate virtual samples for the target variable using linear regression\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(x, y)\n",
    "y_vs = model.predict(x_new)\n",
    "y_new = y_vs\n",
    "\n",
    "data_new = pd.DataFrame(np.column_stack([x_new, y_new]), columns=list(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b024c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "data_new.hist(bins=20, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7eedea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the feature and target variables\n",
    "homo = data_new['HOMO']\n",
    "ie = data_new['IE']\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(con, ie, c='b')\n",
    "plt.title('Distribution of HOMO')\n",
    "plt.xlabel('HOMO')\n",
    "plt.ylabel('IE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f38da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kolom_x = ['HOMO', 'LUMO', 'Gap Energy', 'Dipole Moment', 'Ionization Potential',\n",
    "       'Electron Affinity', 'Electronegativity', 'Global Hardness',\n",
    "       'Global Softness', 'Electrophilicity',\n",
    "       'Fraction of electron transferred', 'IE']\n",
    "\n",
    "for i in range(len(kolom_x)):\n",
    "    # calculate spearman's correlation\n",
    "    x = data_new[kolom_x[i]]\n",
    "    y = y_new\n",
    "    coef, p = spearmanr(x, y)\n",
    "    print(kolom_x[i],': ', np.round(coef,3))\n",
    "    # interpret the significance\n",
    "    alpha = 0.05\n",
    "    \n",
    "    if p > alpha:\n",
    "        print('Samples are uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "        print()\n",
    "    else:        \n",
    "        print('Samples are correlated (reject H0) p=%.3f' % p)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b72776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV 2\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "for train, test in kfold.split(x_new, y_new):\n",
    "    x_train, x_test = x_new[train], x_new[test]\n",
    "    y_train, y_test = y_new[train], y_new[test]\n",
    "\n",
    "# Model\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Prediksi\n",
    "y_pred_train = model.predict(x_train)\n",
    "y_pred_test = model.predict(x_test)\n",
    "        \n",
    "print('Training')\n",
    "print('R^2 :', r2_score(y_train, y_pred_train))\n",
    "print('MAE :', mean_absolute_error(y_train, y_pred_train))\n",
    "print('MAPE:', mean_absolute_percentage_error(y_train, y_pred_train))\n",
    "print('MSE :', mean_squared_error(y_train, y_pred_train))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "print('================================')\n",
    "print('Testing')\n",
    "print('R^2 :', r2_score(y_test, y_pred_test))\n",
    "print('MAE :', mean_absolute_error(y_test, y_pred_test))\n",
    "print('MAPE:', mean_absolute_percentage_error(y_test, y_pred_test))\n",
    "print('MSE :', mean_squared_error(y_test, y_pred_test))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "\n",
    "# Plot\n",
    "xline   = np.array(np.linspace(np.min(y)-0.1, np.max(y)+0.1, 150))\n",
    "yline   = np.array(np.linspace(np.min(y)-0.1, np.max(y)+0.1, 150))\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.scatter(y_train, y_pred_train, c='blue', label = \"Training\")\n",
    "plt.scatter(y_test, y_pred_test, c='red', label = \"Testing\")\n",
    "plt.plot(xline, yline, color=\"black\", label = \"actual line\", linestyle='dotted')   \n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
